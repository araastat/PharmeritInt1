---
title       : Intermediate R Part I
subtitle    : Pharmerit, LLC
author      : Abhijit Dasgupta
job         : ARAASTAT
github:
  user: araastat
  repo : PharmeritInt1
  branch: "master"
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme : solarized-light
widgets     : [mathjax, bootstrap]      # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
logo : Rlogo-1.png
license : by-nc-nd
--- .segue .dark

## Generalized linear models
```{r, results='hide',echo=FALSE}
opts_chunk$set(comment=NA, prompt=TRUE)

```


---

## A quick review of GLMs

Generalized linear models are extensions of linear models, that are based on the exponential
family of distributions. They are characterized by three components:

+ A distribution (normal/Gaussian, exponential, binomial, Poisson, Weibull, and so on)
+ A linear predictor $\eta = X\beta$
+ A _link function_ relating the expected outcome to the predictor: $E(Y) = \mu = g^{-1}(\eta)$. There are standard or "natural" links for different distributions, giving rise to familiar models

This framework includes several classical models:

1. Ordinary least squares / linear regression
2. Logistic regression (Note, probit and tobit regressions involve changing the link, but in the same framework)
3. Poisson regression / log-linear models
4. Weibull regression

---

## Linear regression

We want to model a structure
$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \varepsilon
$$
from data, estimate the coefficients $\beta$, obtain their standard errors, and
perform statistical inference (hypothesis testing, confidence intervals)

---

## Linear regression

```{r LinearRegression1, eval=TRUE}
data(mtcars)
model1 <- lm(mpg ~ disp + hp + drat + wt + as.factor(cyl) + as.factor(gear),
             data = mtcars)
```
```{r, echo=FALSE}
model1
```

---

## Linear regression

Arguments:
```{r}
args(lm)
```

Results
```{r}
names(model1)
```

---

## Linear regression

```{r, results='hide'}
summ1 <- summary(model1)
```
```{r, echo=FALSE}
summ1
```

---

## Linear regression

```{r}
summ1$coef
```
```{r}
class(summ1$coef)
```

---

## Linear regression
```{r, out.height='450px'}
par(mfrow=c(2,2)) # Arrange in 2x2 grid
plot(model1)
```

---
## Linear regression


```{r, results='asis'}
require(xtable)
print(xtable(model1), type='html')
```

---

## Generalized linear models

The way you do GLM's in R is basically the same as doing linear regression.

You just have to specify a distribution and link.

What you specify is a `family`, i.e., a family of distributions, with a link specification.

---

## Logistic regression

Logistic regression can be run if the outcome _Y_ is either a __binary__ or a 
__binomial__ variable.

```{r}
data(infert)
model2 <- glm(case~spontaneous + induced, data=infert, family=binomial())
model2
```

---

## Logistic regression

```{r}
summary(model2)$coef
```
Coefficients are interpreted as log-odds ratios.

---

## Logistic regression

If you data is binomial rather than binary, specify number of successes and failures as the outcome

```{r}
for(i in 1:3) esoph[,i] <- as.factor(as.character(esoph[,i]))
model3 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp, data=esoph,
              family=binomial())
model3
```

*** pnotes


`tobgp * alcgp` is the same as `tobgp + alcgp + tobgp:alcgp`, i.e., main effects 
 and multiplicative interaction

---
## Poisson regression

```{r}
counts <- c(18,17,15,20,10,20,25,13,12)
outcome <- gl(3,1,9)
treatment <- gl(3,3)
d.AD <- data.frame(treatment, outcome, counts)
model4 <- glm(counts ~ outcome + treatment, family = poisson())
model4
```

---
## Poisson regression
```{r}
summary(model4)$coef
```
Coefficients are interpreted as log-ratios.

---
## Poisson regression
```{r, results='asis'}
print(xtable(model4), type='html')
```

--- .segue .dark

## Predictive modeling

---

## Prediction vs interpretation

+ Predictive modeling is focused on getting the best possible prediction
+ Interpretation of the model is a secondary or even an ignored issue
+ Some interpretation is possible, using counterfactual arguments (Dasgupta, et al, _under review_)

----
## Predictive modeling

+ Since the emphasis is on prediction, we need to 
  -  evaluate predictive performance rather than fit
  - be aware of _overfitting_
  - evaluate the model on a dataset other than where it is fitted and trained
  

---

## Predictive modeling

+ The usual nomemclature defines two data sets
  - Training set, where model is build
  - Test set, where model performance is evaluated

+ This typically involves splitting the data into
  + 2 random parts
  + several (5 or 10) random parts for cross-validation
  
+ What you report is the prediction error or some surrogate
  + Root Mean Square Error (RMSE) for continuous outcomes
  + Brier score, misclassification rate, AUC for categorical variables

---

## Splitting data

```{r, results='hide'}
set.seed(135793)
library(caret)
indx.train <- createDataPartition(y=1:nrow(mtcars), p=0.7, list=F)
mtcars.train <- mtcars[indx.train,]
mtcars.test <- mtcars[-indx.train,]
```

---
## Random Forests

```{r, out.height='400px'}
require(randomForest)
rf1 <- randomForest(mpg~., data=mtcars.train, importance=T)
varImpPlot(rf1)
```

*** pnotes

`mpg ~ .` means `mpg` regressed on all other variables in the data.frame

---
## Random Forests

```{r,out.height="400px", message=FALSE, fig.align='center'}
library(ggplot2)
p1 <- predict(rf1, newdata=mtcars.test)
qplot(mtcars.test$mpg, p1, xlab='True', ylab='predicted')+
  geom_abline(color='red') +
  geom_smooth()
```

---
## Random Forests

### Compute the RMSE of this prediction

*** pnotes

```{r}
sqrt(mean((mtcars$mpg - p1)^2))
```

---
## Classification

```{r, message=FALSE}
library(AppliedPredictiveModeling)
data(twoClassData, package='AppliedPredictiveModeling')
twocl <- cbind(classes, predictors)
indx.train <- createDataPartition(twocl$classes,p=.5, list=F)
twocl.train <- twocl[indx.train,]
twocl.test <- twocl[-indx.train,]
str(twocl)
```

---
## Classification
```{r, message=F, cache=TRUE}
library(gbm)
twocl.train <- transform(twocl.train, classes1=ifelse(classes=='Class2',1,0))
twocl.test <- transform(twocl.test, classes1=ifelse(classes=='Class2',1,0))
model5 <- gbm(classes1~., data=twocl.train, n.trees=1000,cv.folds=5)
p5 <- predict(model5, newdata=twocl.test, n.trees=500, type='response')
```

```{r}
model6 <- randomForest(classes~., data=twocl.train)
p6 <- predict(model6, newdata=twocl.test, type='prob')[,2]
```

---

## Classification errors

Misclassification
```{r}
misclas5 <- mean((twocl.test$classes=='Class2') != (p5 > 0.5))
misclas6 <- mean(twocl.test$classes != predict(model6, newdata=twocl.test))
data.frame('GBM'=misclas5, 'RF'=misclas6)
```

---
## ROC curves

```{r,out.height='400px'}
library(ROCR)
pred5 <- prediction(p5, twocl.test$classes)
perf5 <- performance(pred5, 'tpr','fpr')
plot(perf5)
```

---
## ROC curves

```{r,out.height='400px'}
library(ROCR)
pred6 <- prediction(p6, twocl.test$classes)
perf6 <- performance(pred6, 'tpr','fpr')
plot(perf6)
```

---
## AUC

```{r}
extract.auc <- function(pred){
  require(ROCR)
  perf <- performance(pred, 'auc')
  paste('AUC =', perf@y.values)
}
data.frame("GBM"=extract.auc(pred5), "RF"=extract.auc(pred6))
```

---.segue .dark

## Discrete event simulation

---

## The M/M/1 process

The M/M/1 process has a single server who serves incoming clients. 

1. Clients come into the queue according to a Poisson process with rate $\lambda$
2. Service time follows an exponential distribution with rate $\mu$
3. Want to see how many people are in the system.

---
## Initialization

```{r, results='hide'}
t.end   <- 10^5 # duration of sim
t.clock <- 0    # sim time
Ta <- 1.3333    # interarrival period
Ts <- 1.0000    # service period
t1 <- 0         # time for next arrival
t2 <- t.end     # time for next departure
tn <- t.clock   # tmp var for last event time
tb <- 0         # tmp var for last busy-time start
n <- 0          # number in system
b <- 0          # total busy time
c <- 0          # total completions
qc <- 0         # plot instantaneous q size
tc <- 0         # plot time delta
plotSamples <- 100
set.seed(1)
```

---
## Running the simulation

The code is [here](rundes.R)
```{r,eval=FALSE}
source('rundes.R')
```


---

## Plotting a result

```{r, eval=FALSE}
plot(tc,qc,type='s',xlab='Time',ylab='Instantaneous queue length', 
     main='M/M/1 simulation')
```{r, out.height='400px', echo=FALSE}
source('rundes.R')
```

---.segue .dark

## Reporting to Microsoft Products

---

## Option 1

This option uses a Windows-only package called `R2wd`, which uses the DCOM service on Microsoft operating systems

__This may be a security risk__. Don't know

```{r, eval=FALSE}
library(R2wd)
wdGet() # Opens new Word doc if not already open
wdTable(format(head(mtcars)))
wdPlot(rnorm(100), plotfun = plot, height = 10, width =20, pointsize = 20)

```

See [this page](http://www.r-statistics.com/2010/05/exporting-r-output-to-ms-word-with-r2wd-an-example-session/) for a worked out example. 

---

## Option 2 (cross-platform)

Using pandoc and `pander` to create Word documents

```{r, eval=FALSE}
library(pander)
myReport <- pander::Pandoc$new('Abhijit','demo')
myReport$add(model1)
myReport$add(model4)
myReport$add.paragraph("Now here's a plot!!")
myReport$add(plot(perf6))
myReport$format <- 'html'
myReport$export(open=F)
```


---.segue .dark

## Thank you

```{r, echo=FALSE, results='hide', message=FALSE}
purl('index.Rmd',output='code.R', documentation=0L)
```

---